[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "assignment-1.html",
    "href": "assignment-1.html",
    "title": "Quantitative Methods - Workshop, Assigments and Tutorials",
    "section": "",
    "text": "References\n\nHalperin, I., D. B. Pyne, and D. T. Martin. 2015. “Threats to Internal Validity in Exercise Science: A Review of Overlooked Confounding Variables.” Journal Article. Int J Sports Physiol Perform 10 (7): 823–29. https://doi.org/10.1123/ijspp.2014-0566.\n\n\nHopkins, W. G. 2000. “Measures of Reliability in Sports Medicine and Science.” Journal Article. Sports Med 30 (1): 1–15. http://www.ncbi.nlm.nih.gov/pubmed/10907753.\n\n\nTanner, R. K., and C. J. Gore. 2012. Physiological Tests for Elite Athletes 2nd Edition. Book. Human Kinetics. https://books.google.no/books?id=0OPIiMks58MC."
  },
  {
    "objectID": "assignment-2.html",
    "href": "assignment-2.html",
    "title": "Quantitative Methods - Workshop, Assigments and Tutorials",
    "section": "",
    "text": "References\n\nCampbell, Michael J., Stephen John Walters, and David Machin. 2020. Medical Statistics: A Textbook for the Health Sciences. Fifth edition. Hoboken, NJ: Wiley-Blackwell.\n\n\nFrigessi, Arnoldo, and Odd O Aalen. 2018. Statistiske Metoder i Medisin Og Helsefag. Oslo: Gyldendal akademisk.\n\n\nNewell, J., D. Higgins, N. Madden, J. Cruickshank, J. Einbeck, K. McMillan, and R. McDonald. 2007. “Software for Calculating Blood Lactate Endurance Markers.” Journal Article. Journal of Sports Sciences 25 (12): 1403–9. https://doi.org/10.1080/02640410601128922.\n\n\nSpiegelhalter, D. J. 2019. The Art of Statistics : How to Learn from Data. Book. First US edition. New York: Basic Books.\n\n\nTanner, R. K., and C. J. Gore. 2012. Physiological Tests for Elite Athletes 2nd Edition. Book. Human Kinetics. https://books.google.no/books?id=0OPIiMks58MC."
  },
  {
    "objectID": "assignment-3.html",
    "href": "assignment-3.html",
    "title": "Quantitative Methods - Workshop, Assigments and Tutorials",
    "section": "",
    "text": "This assignment is set up as a statistical laboratory, we will perform simulations and your assignment is to interpret and explain the results. Create a report based on the code used in the lab and make sure you answer the specified questions (1-8). You can be as creative as you want and explore the results further.\nThe report should be handed in on canvas as a link to github repository containing a reproducible .Rmd (or qmd) file.\n\n\nIn this assignment we will simulate a population of possible values, from this population we will draw random samples, calculate statistics and interpret them. The population of values can be regarded as the possible differences between two treatments in a cross-over study where participants have performed both treatments. The values in the population are calculate as \\(Treatment - Control\\).\nWe will simulate a population of one million numbers with a mean of 1.5 and a standard deviation of 3. We will make two different set of studies, one set with a sample size of 8 and one set with a sample size of 40. In order to be sure you replicate your results, include and run set.seed() before simulations in your final script.\nWe will use the lm function to estimate the average value of the population. We do this in an “intercept-only” model. This model can be written as\n\\[Y_i = \\beta_0 + \\epsilon_i\\]\nwhere \\(\\beta_0\\) is the intercept and can be interpreted as the average value of \\(Y\\), our dependent variable. \\(\\epsilon\\) is the error term, each observation (\\(i\\)) deviates from the intercept to some degree. If the intercept term is positive or negative we can interpret it as a difference between the two treatments (described above). This model is equivalent to a one-sample t-test. Let’s get started!\nIn the code chunk below, we will simulate the population of differences between treatments. We will then draw two random samples corresponding sample sizes of 8 and 40 and save these data in data frames with the dependent variable named y. We fit the very simple model y ~ 1 as a linear model and save the model object as m1 and m2.\n\nlibrary(tidyverse)\n\nset.seed(1)\npopulation <- rnorm(1000000, mean = 1.5, sd = 3)\n\n\nsamp1 <- data.frame(y = sample(population, 8, replace = FALSE))\n\nsamp2 <- data.frame(y = sample(population, 40, replace = FALSE))\n\n\nm1 <- lm(y ~ 1, data = samp1)\nm2 <- lm(y ~ 1, data = samp2)\n\nsummary(m1)\n\n\nCall:\nlm(formula = y ~ 1, data = samp1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.5322 -1.2523 -0.0883  1.3540  4.8692 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)    1.840      1.251    1.47    0.185\n\nResidual standard error: 3.539 on 7 degrees of freedom\n\n\nThe results from a simple model can be calculated by hand. The Estimate corresponds to the average of all values in the sample, from the smaller sample, samp1 we can do mean(samp1$y). This average should correspond to coef(m1) which should be 1.84. The variation of the data is most often described with the standard deviation (SD). The SD of y in the smaller sample is sd(samp1$y) (corresponding to 3.539). However, the regression table (summary(m1)) show you the standard error (SE). This statistic is an attempt to estimate the variation in a hypothetical distribution of means. The standard error is (in this simple case) \\(SE_y = \\frac{SD_y}{\\sqrt{n}}\\). Calculating by hand using the data in samp1 we would do sd(samp1$y)/sqrt(8). Amazingly this corresponds to 1.251!\nBy using the estimate 1.84 and the corresponding SE (1.251) we can calculate the t-value as the ratio \\(\\frac{Estimate}{SE}\\). The t-value may in turn be used to determine the are under the curve of a t-distribution. The t-value from the above calculation is 1.4702611. Using our single \\(n=8\\) study, we estimate that values of t, as extreme or even more extreme as our observed value both above and below 0, would occur in 18.5% of studies if the null-hypothesis was true. This corresponds to a p-value of 0.185. The figure below shows a graphical representation of a t-value distribution under the assumption that the null-hypothesis is true.\n\n\n\n\n\nA t-distribution estimated from model m1 with the shaded area corresponding to the observed p-value.\n\n\n\n\n\nIn light of what you know now about the process of conducting a study with a random sample, use your own words and…\n\nExplain the estimate, SE, t-value, and p-value from the regression models that we created previously (m1 and m2).\nDiscuss what contributes to the different results in the two studies (m1 and m2).\nWhy do we use the shaded area in the lower and upper tail of the t-distribution (See Figure @ref(fig:t-dist-fig)).\n\n\n\n\n\nBelow we will perform 1000 studies and save the results from each study. This will make it possible for us to get an actual sampling distribution. Copy the code to your own document to run the experiment.\n\n# Create data frames to store the model estimates\nresults_8 <- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 8)  \n\nresults_40 <- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 40)\n\n# A for loop used to sample 1000 studies, each iteration (i) will draw a new sample\n# from the population. \n\nfor(i in 1:1000) {\n  \n  # Draw a sample \n  samp1 <- data.frame(y = sample(population, 8, replace = FALSE))\n  samp2 <- data.frame(y = sample(population, 40, replace = FALSE))\n\n  # Model the data\n  m1 <- lm(y ~ 1, data = samp1)\n  m2 <- lm(y ~ 1, data = samp2)\n  \n  # Extract values from the models\n  results_8[i, 1] <- coef(summary(m1))[1, 1]\n  results_8[i, 2] <- coef(summary(m1))[1, 2]\n  results_8[i, 3] <- coef(summary(m1))[1, 4]\n\n  results_40[i, 1] <- coef(summary(m2))[1, 1]\n  results_40[i, 2] <- coef(summary(m2))[1, 2]\n  results_40[i, 3] <- coef(summary(m2))[1, 4]\n  \n  \n}\n\n\n# Save the results in a combined data frame\n\nresults <- bind_rows(results_8, results_40)\n\n\nUsing the results data frame…\n\nCalculate the standard deviation of the estimate variable, and the average of the se variable for each of the study sample sizes (8 and 40). Explain why these numbers are very similar. How can you define the Standard Error (SE) in light of these calculations?\nCreate a histogram (see example code below) of the p-values from each study sample-size. How do you interpret these histograms, what do they tell you about the effect of sample size on statistical power?\nCalculate the number of studies from each sample size that declare a statistical significant effect (specify a threshold for \\(\\alpha\\), your significance level).\nUsing the pwr package, calculate the power of a one-sample t-test, with a effect size of 1.5/3, your specified significance level and sample sizes 8 and 40. Explain the results in the light of your simulations.\n\n\n\n# Example code for copy and paste\n\n# A two facets histogram can be created with ggplot2\nresults %>%\n  ggplot(aes(pval)) + \n  geom_histogram() +\n  facet_wrap(~ n)\n\n\n# Count the proportion of tests below a certain p-value for each \nresults %>%\n  filter(pval < 0.05) %>%\n  group_by(n) %>%\n  summarise(sig_results = n()/1000)\n\n# Using the pwr package\nlibrary(pwr)\n\npwr.t.test(n = 40, sig.level = 0.05, d = 1.5/3, type = \"one.sample\")\n\n\n\n\nWe will now simulate a population without differences between treatment and control. The code below is very similar to the one we use above, except that we use an average effect of 0 in the population.\n\npopulation <- rnorm(1000000, mean = 0, sd = 3)\n\n\n# Create data frames to store the model estimates\nresults_8 <- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 8)  \n\nresults_40 <- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 40)\n\n# A for loop used to sample 1000 studies, each iteration (i) will draw a new sample\n# from the population. \n\nfor(i in 1:1000) {\n  \n  # Draw a sample \n  samp1 <- data.frame(y = sample(population, 8, replace = FALSE))\n  samp2 <- data.frame(y = sample(population, 40, replace = FALSE))\n\n  # Model the data\n  m1 <- lm(y ~ 1, data = samp1)\n  m2 <- lm(y ~ 1, data = samp2)\n  \n  # Extract values from the models\n  results_8[i, 1] <- coef(summary(m1))[1, 1]\n  results_8[i, 2] <- coef(summary(m1))[1, 2]\n  results_8[i, 3] <- coef(summary(m1))[1, 4]\n\n  results_40[i, 1] <- coef(summary(m2))[1, 1]\n  results_40[i, 2] <- coef(summary(m2))[1, 2]\n  results_40[i, 3] <- coef(summary(m2))[1, 4]\n  \n  \n}\n\n\n# Save the results in a combined data frame\n\nresults_null <- bind_rows(results_8, results_40)\n\n\nUsing the new data frame with results from studies of a population with an average effect of zero, create new histograms.\n\nWith a significance level of 5%, how many studies would give you a “false positive” result if you did many repeated studies?"
  },
  {
    "objectID": "assignment-4.html",
    "href": "assignment-4.html",
    "title": "Quantitative Methods - Workshop, Assigments and Tutorials",
    "section": "",
    "text": "Footnotes\n\n\nAvoid using review articles or meta-analyses↩︎\nSee Teaching undergraduate students to read empirical articles: An evaluation and revision of the QALMRI method, this advice was also heavily influenced by this website↩︎\nHulley, S. B. (2013). Designing clinical research. Philadelphia, Wolters Kluwer/Lippincott Williams & Wilkins.↩︎"
  },
  {
    "objectID": "assignment-5.html",
    "href": "assignment-5.html",
    "title": "Quantitative Methods - Workshop, Assigments and Tutorials",
    "section": "",
    "text": "References\n\nHammarström, Daniel, Sjur Øfsteng, Lise Koll, Marita Hanestadhaugen, Ivana Hollan, William Apró, Jon Elling Whist, Eva Blomstrand, Bent R. Rønnestad, and Stian Ellefsen. 2020. “Benefits of Higher Resistance-Training Volume Are Related to Ribosome Biogenesis.” Journal Article. The Journal of Physiology 598 (3): 543–65. https://doi.org/10.1113/JP278455."
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Assignments",
    "section": "",
    "text": "a Select one laboratory assignments for your portfolio exam. All groups presents one selected method on 2021-11-23. b This assignment is presented in connection with lectures."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Quantitative methods and statistics (In Sport and Exercise Science)",
    "section": "",
    "text": "Welcome to the course Quantitative methods and Statistics (IDR4000). The course aims to give students an overview of methodological aspects within the field of sport and exercise-physiology. Specifically, planning, conducting and analysing research projects with human participants will be covered. The lecture notes for the course can be found here. This website will contain tutorials that we will work on in class, assignments and additional materials related to the course content."
  },
  {
    "objectID": "index.html#practical-information",
    "href": "index.html#practical-information",
    "title": "Quantitative methods and statistics (In Sport and Exercise Science)",
    "section": "Practical information",
    "text": "Practical information\nThese notes were updated on 2022-09-20 and cover the course held during 2022 autumn semester. Contact Daniel Hammarström if you have any questions regarding this content.\n\nLearning objectives\nLearning objectives can be read in Norwegian here.\n\n\nLearning strategies\nThe course will include lectures, laboratory exercises, computer exercises and workshops, seminars and student presentations. Lectures will be held in-person and as pre-recorded published on these websites.\nComputer exercises will eventually require that you have special computer software installed on your computer. The software is free (see specific chapters in lecture notes).\nAssignments will be presented on this website with information on how to hand them in. The whole course is evaluated based on a portfolio exam (see below).\n\n\nCourse evaluation\nAs a student you can contribute to the quality of the course by engaging in course evaluation throughout the course. You will be asked to answer a pre-course questionnaire about your expectations and a post-course questionnaire about your experiences. You are also welcomed to take part in systematic discussions during the course about the quality of teaching and course material. With these notes I want to underline the importance of student participation in the continuous development of the course (and program) teaching/learning quality.\n\n\nLecturers and course administration\nIn order of appearance\n\nDaniel Hammarström (daniel.hammarstrom@inn.no), is responsible for course administration and will be teaching statistics.\nTomas Urianstad will organize laboratory work in the physiology lab.\nKristian Lian will be involved in molecular methods.\nProf. Carsten Lundby will cover aspects CO2 re-breathing techniques (physiology).\nProf. Finnur Dellsén will cover philosophy of science.\nProf. Stian Ellefsen will teach molecular methods.\n\n\n\nUpdates, notifications and general communication\nThese course notes will be updated during the course. General information and last minute changes will be posted on Canvas, make sure to check it as part of your daily study routine.\n\n\nLiterature\nA full list of recommended literature can be found here. Literature will be referenced in specific sections in the lecture notes.\n\n\nGrades\nThe course is graded pass/fail.\n\n\nLanguage\nMy (Daniel) first language is Swedish, I’m sure most of you will understand what I’m talking about. However, due to the fact that we accept international students to the program, most written communication and some lectures will be in English. You are not expected to write in English, it is however possible!"
  },
  {
    "objectID": "index.html#assignments-and-portfolio-exam",
    "href": "index.html#assignments-and-portfolio-exam",
    "title": "Quantitative methods and statistics (In Sport and Exercise Science)",
    "section": "Assignments and Portfolio exam",
    "text": "Assignments and Portfolio exam\nThe course is based on several assignments. Some of these assignments are to be handed in as part of a portfolio exam upon which your grade is based.\nAssignments that are due during the course (arbeidskrav) are expected to be further improved after feedback from fellow students and teachers before inclusion in your portfolio.\nThe table below shows all assignments that are part of the course. Some are not to be included in the portfolio and some assignments are group assignments (see Table). In addition to these assignments, non-mandatory homework will be presented during the course.\n\n\n\nAssignment\nDue date\nIncluded in portfolio\nGroup assignment\n\n\n\n\nDescriptive statistics, reliability and validity, tools for reproducible data science\n2022-09-26\nYes\nYes\n\n\nRegression models and prediction from data\n2022-10-03\nNo\nYes\n\n\nExtraction and analysis of DNA\n2022-11-25\nOptionala\nYes\n\n\nExtraction of RNA and analysis of qPCR experiments\n2022-11-25\nOptionala\nYes\n\n\nExtraction and analysis of Protein\n2022-11-25\nOptionala\nYes\n\n\nPhilosophy of scienceb (See canvas)\n2022-10-28\nYes\nNo\n\n\nDrawing inference from statistical models and statistical power\n2022-11-07\nNo\nYes\n\n\nStudy designs\n2022-11-17\nYes\nNo\n\n\nAnalyzing repeated measures experiments\n2022-11-21\nYes\nNo\n\n\n\na Select one laboratory assignments for your portfolio exam. All groups presents one selected method on 2021-11-23. b This assignment is presented in connection with lectures. \nIn addition to arbeidskrav/assignments, you are required to contribute to the course wiki. The wiki page is hosted at github.com/dhammarstrom/IDR4000-2022/. In order to contribute you need to set up your own github account. The language of the wiki should be Norwegian.\nSmaller assignments and quizzes are presented as part of the course, but you are not required to do them to pass the course."
  },
  {
    "objectID": "index.html#other-information",
    "href": "index.html#other-information",
    "title": "Quantitative methods and statistics (In Sport and Exercise Science)",
    "section": "Other information",
    "text": "Other information"
  },
  {
    "objectID": "workshops.html",
    "href": "workshops.html",
    "title": "Workshops",
    "section": "",
    "text": "Workshop\nAdditional material\n\n\n\n\nIntroduction to data science (Norwegian)\n\n\n\nInstalling and starting R\n\n\n\nCreating your first graph\n\n\n\nData wrangling and tables\n\n\n\nData wrangling and tables, part 2\n\n\n\nWriting reports\n\n\n\nCollaborative coding"
  },
  {
    "objectID": "ws1-data-science-intro.html",
    "href": "ws1-data-science-intro.html",
    "title": "Quantitative Methods - Workshop, Assigments and Tutorials",
    "section": "",
    "text": "References\n\nBroman, Karl W., and Kara H. Woo. 2018. “Data Organization in Spreadsheets.” Journal Article. The American Statistician 72 (1): 2–10. https://doi.org/10.1080/00031305.2017.1375989."
  },
  {
    "objectID": "ws2-installing-r.html",
    "href": "ws2-installing-r.html",
    "title": "Quantitative Methods - Workshop, Assigments and Tutorials",
    "section": "",
    "text": "Footnotes\n\n\nA more elaborate description can be found at the CRAN FAQ↩︎"
  },
  {
    "objectID": "ws3-first-graph.html",
    "href": "ws3-first-graph.html",
    "title": "Quantitative Methods - Workshop, Assigments and Tutorials",
    "section": "",
    "text": "In this workshop, many of us will create our first real plot. For this purpose we will use the ggplot2 package. This choice of package is based on usage, many people use it and therefore you can easily find help online. ggplot2 is also integrated or highly compatible with other commonly used packages in R.\nIt is a good idea to write your code in a R script in this session. Be sure to comment your code extensively, this will help you explain to yourself what you are doing and make it easy to reuse parts of your code.\nA commented line in R code starts with #:\n\n# This is a comments\na <- c(\"roses\", \"are\", \"red\")\n# This is another comment\n\n#### Sections can be specified with several number/hash/pound signs ####\n\n# Sections in scripts and code chunks help you structure your work. \n# In R studio, sections can be located from the editor.\n\nIt is also a good idea to use the comments to write a statement about the purpose of the script or analysis your are writing. Later we will talk about keeping files in a structured way in projects.\n\n\nWe need to start by installing required packages. From the console we can type\n\ninstall.packages(\"tidyverse\")\n\nThis will install the tidyverse package, a package containing many package. On the tidyverse website you can read:\n\nThe tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures.\n\nBy using the tidyverse you will adopt a special dialect of R. A dialect that is very efficient and fairly easy to read (as a human).\nTidyverse will install ggplot2 for you. Notice that you only need to install a package once. It is therefore not a good idea to have an unconditional install.packages() in your script.\nTo get ggplot2 to start working we need to use another command:\n\nlibrary(\"ggplot2\")\n\nNotice that I’ve put ggplot2 inside citation marks \". This is optional!\nThe library function loads all function contained in the package to your R session. This means that you can access and use them.\nFor these exercises we will use another package. The exscidata package contains data sets related to exercise physiology. To install it we need a bit more code. Since exscidata is not on CRAN, but on github we can use the remotes package.\n\n# Install package from cran\nif(!(\"remotes\" %in% .packages(all.available = TRUE))) {\n        install.packages(\"remotes\")\n}\n\n\n# Using remotes, install exscidata from github\nif(!(\"exscidata\" %in% .packages(all.available = TRUE))) {\n        remotes::install_github(\"dhammarstrom/exscidata\")\n}\n\n\n\n# Load the exscidata package\nlibrary(exscidata)\n\n\n\n\n\n\n\nNote\n\n\n\nAbove is a if statement. Ordinarily, the statement can be read as: “If the condition is TRUE, then do whatever is in the brackets”. However, we also use a ! around a parentheses containing the %in% operator. The ! negates the test. If the package name is not contained in the vector of all packages created by the .packages(all.available = TRUE), then we want to install the package.\nThis is a way not having to install packages that are already installed when running your script.\n\n\nWe are now set to load data into our session.\n\n\n\nThe data set we will use in these exercises is called cyclingstudy. You can have a look at the variables by using the help command ?cyclingstudy.\nTo load data from a package we can use data(\"cyclingstudy\")\n\n\n\n\n\n\nReview your understanding\n\n\n\n\n\n\nExplain the difference between install.packages() and library()\nWhat is the tidyverse, what will we use ggplot2 for?\nWhat does it mean when a package is not on CRAN?\nIdentify at least one numeric variable in the help pages for cyclingstudy, identify at least one categorical variable.\nWhat happens in your environment when you type data(\"cyclingstudy\")?\n\n\n\n\nA data set can be accessed in multiple ways. We may want to see the data. We can do this by typing View(cyclingstudy) in the console (notice the capital V). Or we can show a couple of rows and columns in the console by typing cyclingstudy.\n\n\n\nThe ggplot function (from the ggplot2 package) takes quite a lot of arguments. However, very few are needed to create a graph.\nThe ggplot2 system uses:\n\ndata → The dataset containing variables to plot\naesthetics → Scales where the data are mapped\ngeometries → Geometric representations of the data\nfacet → A part of the dataset\nstatistical transformations → Summaries of data\ncoordinates → The coordinate space\nthemes → Plot components not linked to data\n\nWe build a graph by mapping variables to different locations and visual characteristics of what is called geoms. This system makes it easy to build different types of graphs using similar syntax.\nWe will start by mapping to continuous variables to the coordinate system. For this exercise, use the variables weight.T1 and sj.max.\nggplot needs to know were the variables can be found, we therefore have to specify the data argument first. Next we map the variables to the x and y coordinates of the graph. You can copy the code below to your R script.\n\nggplot(data = cyclingstudy, aes(x = cmj.max, y = sj.max))\n\n\n\n\n\n\n\nReview your understanding\n\n\n\n\n\n\nExplain to your friend what we have done so far.\nWhat is mapping in this context?\nDefine “continuous variables”\n\n\n\n\n\n\n\nWe have not yet added graphical representations of the data mapped to coordinates (x and y). These can be added to the plot using the + operator, as we will do below.\nThink about a ggplot as a layered construction. Layers can be added (+) to build the graph you want. Layers are added to the graph sequentially, this means it matters in which order you add them.\nBut what to add?\nThere are many geoms, for an overview go to Help > Cheat Sheets > Data Visualization with ggplot2\n\n\n\n\n\n\nPractice\n\n\n\nTask 1: Identify a geom suitable for two continuous variables, that will show individual data points on x- and y- coordinates.\nTask 2: Call up the help page of the selected geom and find out what you need to add as arguments to the geom\n\n\n\n\n\n\n\n\nReview your understanding\n\n\n\n\n\n\nExplain what the argument inherit.aes = TRUE means.\nExplain the sentence (from the help page): “If NULL, the default, the data is inherited from the plot data as specified in the call to ggplot().\n\n\n\n\nBy adding, for example, points to the plot, we will be able to see the data. How would you add the geom that creates points to your plot?\n\n\nShow the code for a possible solution\nggplot(data = cyclingstudy, aes(x = cmj.max, y = sj.max)) + geom_point()\n\n\n\n\n\n\n\n\nGroup work\n\n\n\n\nTask 1: Using the cheat sheet, beside x and y. What other aesthetics (aes) may be added to the plot that will affect the appearance of the points?\nTask 2: Using pen and paper, draw a figure of the cyclingstudy data using one categorical variable and one continuous variable and hand the figure to the next group.\nTask 3: Code the figure! Create the figure that the other group has drafted for you.\n\n\n\n\n\n\nCharacteristics such as shapes or colors can also be added to geoms outside the aes(). This means we will override any mapping already given in aes(). As we already have seen, mappings that are inherited from the ggplot function to geoms.\n\n\n\n\n\n\n\n\nPractice\n\n\n\n\nTask 1: Change characteristics of your plot outside data mapping using color and fill, linetype, size and shape. What geoms are responsive to each change?\n\n\n\n\n\n\n\n\n\nReview your understanding\n\n\n\n\n\n\nExplain the what the code will produce, without running the code below (google “r shapes” to see what number each shape has.)\n\n\n# Example 1\nggplot(data = cyclingstudy, aes(x = cmj.max, y = sj.max, color = group)) + geom_point(color = \"blue\")\n\n# Example 2\nggplot(data = cyclingstudy, aes(x = cmj.max, y = sj.max, color = group)) + geom_point(shape = 8)\n\n# Example 3\nggplot(data = cyclingstudy, aes(x = cmj.max, y = sj.max, color = weight.T1)) + geom_point(shape = 8)\n\n# Example 4\nggplot(data = cyclingstudy, aes(x = cmj.max, y = sj.max, shape = timepoint)) + geom_point(color = \"red\")\n\n\n\n\n\n\n\n\nIn ggplot2 there are pre-set palettes for colors, orders of shapes and line types etc. Often you would want to control such settings.\nThere are many sources for informed selection of colors, one is colorbrewer2. We\nTo change color scales we use scale_*_* functions that will help you set, e.g., colors manually. In the example below we create a gradient from two colors\n\nggplot(data = cyclingstudy, \n       aes(x = cmj.max, y = sj.max, color = weight.T1)) + \n        geom_point() +\n        scale_colour_gradient(\n                low = \"#e41a1c\",  \n                high = \"#4daf4a\")\n\nDiscrete variables can also be set with colors using scale_color_manual\n\nggplot(data = cyclingstudy, \n       aes(x = cmj.max, y = sj.max, color = timepoint)) + \n        geom_point() +\n        scale_color_manual(values = c(\"#66c2a5\",\"#fc8d62\",\"#8da0cb\",\"#e78ac3\"))\n\n\n\n\n\n\n\nReview your understanding\n\n\n\n\n\n\nExplain to a friend what scales do\n\n\n\n\n\n\n\nSome aspects of a plot requires that data points are connected together. This essentially means that some a variable needs to group data points. In our example data set, subject gives the identity of each participant. We may use this information to group data points, or connect them with e.g. geom_line(). By adding group = subject to the aes() call in ggplot we will group all geoms that allow grouping.\n\n\n\n\n\n\nReview your understanding\n\n\n\n\n\n\nBefore running the code below. Explain what you expect it will show.\n\n\n\n\n\n# Example 1\nggplot(data = cyclingstudy, aes(x = cmj.max, \n                                y = sj.max, \n                                color = group,\n                                shape = timepoint,\n                                group = subject)) + \n        geom_point() +\n        geom_line()\n\n\n\n\nA plot can be quite cluttered, and in this case, give a false impression of a lot of data. The design of this study results in a data set where each participant is tested at multiple time-points. We can therefore create facets based on some aspect of the data, such as time-point.\nThe facet_wrap() and facet_grid() creates facets.\n\n# Example 1\nggplot(data = cyclingstudy, aes(x = cmj.max, \n                                y = sj.max, \n                                color = group)) + \n        geom_point() +\n        facet_wrap(~ timepoint)\n\nAs can be seen in the code above, facet_wrap takes a one-handed formula, the ~ (tilde), indicates a formula. We can read this as “wrap by time-point”.\nIn facet_grid() we will use a two-handed formula, meaning that both sides of the tilde needs information. If we want to group only by rows, we will use a . to indicate that nothing will be used to group by column.\n\nggplot(data = cyclingstudy, aes(x = cmj.max, \n                                y = sj.max, \n                                color = group)) + \n        geom_point() +\n        facet_grid( timepoint ~ .)\n\nIn facet_grid above, we could replace the . with another variable. How would you write the code to facet the graph by group in rows and time-point in columns?\n\n\nShow the code\nggplot(data = cyclingstudy, aes(x = cmj.max, \n                                y = sj.max, \n                                color = group)) + \n        geom_point() +\n        facet_grid( group ~ timepoint)\n\n\n\n\n\n\n\n\nReview your understanding\n\n\n\n\n\n\nExplain to a friend, what do the plot produced by the code above show? Include everything that is important to reproduce the plot in your description. Try to describe it without pointing at the plot!\n\n\n\n\n\n\n\nAnnotations can be added to plots, these are often user specified, such as labels and plot titles.\nWe specify labels with the labs() function and add annotations with the annotate() function.\n\nggplot(data = cyclingstudy, aes(x = cmj.max, \n                                y = sj.max, \n                                color = group)) + \n        geom_point() +\n        labs(x = \"Maximal Counter movement jump height (cm)\", \n             y = \"Maximal squat jump height (cm)\", \n             title = \"This is the title\", \n             subtitle = \"This is the subtitle\", \n             caption = \"This is a caption\", \n             color = \"This is the group aesthetics\") +\n        \n        annotate(geom = \"text\", x = 25, y = 35, label = \"This is a text annotation\")\n\nNotice that labs()makes use of all aesthetic mappings and annotate requires a geom.\n\n\n\nThe theme() function is used for non-data layers in the plot.\n\n\n\nThere are two commonly used system for combining individual plots, patchwork, https://patchwork.data-imaginist.com/ and cowplot, https://cran.r-project.org/web/packages/cowplot/vignettes/introduction.html.\nThe idea here is create figures with multiple individual figures.\npatchwork has a very simple syntax.\n\nlibrary(patchwork)\n\n\na <- ggplot(data = cyclingstudy, aes(x = cmj.max, \n                                y = sj.max, \n                                color = group)) + \n        geom_point() \n\nb <- ggplot(data = cyclingstudy, aes(y = sj.max, \n                                x = group)) + \n        geom_boxplot() \n\n\nc <- ggplot(data = cyclingstudy, aes(x = timepoint, \n                                y = sj.max, \n                                group = subject)) + \n        geom_line() \n\n\n\n(a | b) / c\n\ncowplot uses plot_grid to arrange plots\n\nlibrary(cowplot)\n\nplot_grid(a, b, c, nrow = 2)\n\nplot_grid can also use a “nested” structure.\n\nplot_grid(plot_grid(a, b, nrow = 1), \n          c, nrow = 2)\n\nIn both frameworks, annotations can be added to plots to indicate panels/sub-plots.\n\n\n\nOutput from ggplot2 can be saved from RStudio using the export buttom. However, a more reproducible manner is to save the output using ggsave\n\n\n\n\n\n\n\n\nPractice\n\n\n\n\nTask 1: Create three separate plots from the cycling data set and save them as objects in your environment.\nTask 2: Use cowplot and patchwork to group the plots together.\nTask 3: Save the plot using ggsave, explore the help pages to find what arguments are needed!\n\n\n\n\n\n\n\n\nReproduce figure 1.3 from Spiegelhalter (2019)\n\n\n# download data\nchild_heart <- read_csv(\"https://raw.githubusercontent.com/dspiegel29/ArtofStatistics/master/01-1-2-3-child-heart-survival-times/01-1-child-heart-survival-x.csv\")\n\n\nReproduce figure 2.2 and 2.3\n\n\nbeans <- read.csv(\"https://raw.githubusercontent.com/dspiegel29/ArtofStatistics/master/02-2-3-jelly-bean-counts/02-1-bean-data-full-x.csv\", header = FALSE)"
  },
  {
    "objectID": "ws4-data-wrangling-tables.html",
    "href": "ws4-data-wrangling-tables.html",
    "title": "Quantitative Methods - Workshop, Assigments and Tutorials",
    "section": "",
    "text": "The tidyverse contains two packages with functions used to wrangle data, dplyr and tidyr. On wikipedia we can read that:\n\nData analysts typically spend the majority of their time in the process of data wrangling compared to the actual analysis of the data.\n\nIn the age of data we would be ignorant to teach data analysis without data wrangling\n\n\ndplyr contains verbs used for data manipulation, such as filtering rows, selecting variables and changing or creating variables. Verbs can be used in a pipe and read as sequential operations:\n\n> Take the data **then do** \n> filter based on group **then do**\n> create a new variable **then do**\n> show the data in the console.\n\nThe pipe operations are made possible by another package, magrittr. This package contains the forward pipe operator %>%. The forward pipe operator (%>%) can be read as “then do”. The operator takes the object on the left-hand side and puts it as the first argument in the following function.\nTranslating the “pipe” above from human language to R language using the “tidyverse dialect” looks like this:\n\ndata %>%\n        filter(group == \"xx\") %>%\n        mutate(new.var = old.var + old.var2) %>%\n        print()\n\n\n\n\nWe will use the cyclingstudy data from exscidata in our exercises. Load the required components to your session.\n\n\nShow the code\nlibrary(tidyverse) # loads dplyr etc.\nlibrary(exscidata) # loads the data-package\n\ndata(\"cyclingstudy\")\n\n\n\n\n\nMutate can help you create new variables (or overwrite existing once). In the cycling data set there is a variable called VO2.max, this variable is expressed in absolute units (ml min-1), however, we might want to express it as relative units (ml kg-1 min-1).\n\ncyclingstudy %>%\n        mutate(rel.vo2max = VO2.max / weight.T1) %>%\n        print()\n\nThe mutate function creates new variables (or overwrite existing) in a flexible way. Here we simply use division. Other mathematical operators can similarly be used (+, -, *, etc.).\nNotice the print() function in the end of the pipe. This is used to display the results of any manipulations done in the pipe. Notice also that our new variable is not listed. We might need to select a sub-set of variables to get a better overview. We will do this using the select function.\n\ncyclingstudy %>%\n        mutate(rel.vo2max = VO2.max / weight.T1) %>%\n        select(subject, group, timepoint, age, height.T1, weight.T1, VO2.max, rel.vo2max) %>%\n        print()\n\nThe select function takes variable names as “unquoted” names. We can also select a range of columns using the syntax <from>:<to> where <from> is the first column you would like to select and <to> would be the last. Subsequently the above pipe can be re-written as\n\ncyclingstudy %>%\n        mutate(rel.vo2max = VO2.max / weight.T1) %>%\n        select(subject:weight.T1, VO2.max, rel.vo2max) %>%\n        print()\n\nselect can also be used to re-name variables. Simpler variable names for weight, height and relative V̇O2max could be weight, height, vo2max.kg.\n\ncyclingstudy %>%\n        mutate(rel.vo2max = VO2.max / weight.T1) %>%\n        select(subject:age, height = height.T1, weight = weight.T1, VO2.max,vo2max.kg = rel.vo2max) %>%\n        print()\n\n\n\n\nFiltering is used to select specific observations (rows) of a data set. We filter based on specific conditions such as:\n\nAll values bigger than X\nAll values less than Y\nAll observations than contain A, B or C in variable V.\n\nThe above examples must be translated to formal expressions.\n\n\nAn expression that make comparisons can be\n\nx < y → x less than y\nx > y → x greater than y\nx <= y → x less or equal to y\nx >= y → x greater or equal to y\nx == y → x exactly equal to y\nx != y → x not exactly equal to y\n\nIn the filter function these expressions give either TRUE or FALSE. If TRUE the rows are included in the filtered data frame.\nWe can see the mechanism behind filtering by creating a vector of TRUE and FALSE based on an expression. Let’s say that we want to see which rows has weight.T1 greater than 75.\n\ncyclingstudy$weight.T1 > 75\n\n [1]  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE\n[13]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE\n[25]  TRUE  TRUE  TRUE FALSE  TRUE  TRUE FALSE  TRUE  TRUE FALSE  TRUE  TRUE\n[37]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE    NA  TRUE  TRUE FALSE\n[49]    NA  TRUE FALSE    NA  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[61]  TRUE FALSE  TRUE  TRUE    NA  TRUE  TRUE FALSE  TRUE FALSE FALSE FALSE\n[73]  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n\n\nWe can see that the first row returns a TRUE while the second row returns FALSE.\nUsing the filter function, we just add the expression as an argument in the function and all the rows that comes up TRUE will remain.\n\ncyclingstudy %>%\n        filter(weight.T1 > 75) %>%\n        print()\n\n# A tibble: 60 x 101\n   subject group timepoint   age height.T1 weight.T1 sj.max cmj.max lac.125\n     <dbl> <chr> <chr>     <dbl>     <dbl>     <dbl>  <dbl>   <dbl>   <dbl>\n 1       1 INCR  pre          33       183      80.3   31.0    35.0    1.5 \n 2       3 INCR  pre          39       193      98.1   26.8    28.8    1.17\n 3       4 DECR  pre          37       175      79.2   29.2    30.8    0.88\n 4       5 DECR  pre          31       176      88     31.2    25.8    1.06\n 5       6 INCR  pre          33       168      79.6   34.2    35.3    1.27\n 6       7 MIX   pre          42       180      77.6   30.1    33.0    0.85\n 7       8 MIX   pre          26       179      75.5   32.8    33.2    0.93\n 8       9 MIX   pre          41       185      82.4   22.7    22.4    1.48\n 9      10 INCR  pre          35       187      75.6   29.7    31.1    0.93\n10      13 DECR  pre          41       183      76     34.3    36      1.67\n# ... with 50 more rows, and 92 more variables: lac.175 <dbl>, lac.225 <dbl>,\n#   lac.250 <dbl>, lac.275 <dbl>, lac.300 <dbl>, lac.325 <dbl>, lac.350 <dbl>,\n#   lac.375 <dbl>, VO2.125 <dbl>, VO2.175 <dbl>, VO2.225 <dbl>, VO2.250 <dbl>,\n#   VO2.275 <dbl>, VO2.300 <dbl>, VO2.325 <dbl>, VO2.350 <dbl>, VO2.375 <dbl>,\n#   VCO2.125 <dbl>, VCO2.175 <dbl>, VCO2.225 <dbl>, VCO2.250 <dbl>,\n#   VCO2.275 <dbl>, VCO2.300 <dbl>, VCO2.325 <dbl>, VCO2.350 <dbl>,\n#   VCO2.375 <dbl>, VE.125 <dbl>, VE.175 <dbl>, VE.225 <dbl>, VE.250 <dbl>, ...\n\n\n\n\n\n\n\n\nReview your understanding\n\n\n\n\n\nHow many rows in the cyclingstudy data set has\n\nVO2.max values greater than 6000\nVO2.max values less than 6000\nVO2.max values less or equal to than 5360\nVO2.max values greater or equal to than 5360\nthe value pre in timepoint\nthe a value in timepoint other than pre\n\n\n\n\n\n\n\nLogical operators similarly creates TRUE or FALSE as the basis of filtering operations. These can be used in combination with comparisons.\n\n! x → NOT x\nx & y → x and y\nx | y → x or y\nis.na(x) → returns TRUE if x is NA\n\nWe might want to keep all rows with weight.T1 greater than 80 that are also from the group INCR. This can be solved with an AND operator (&).\n\n#| echo: true\n\ncyclingstudy %>%\n        filter(weight.T1 > 80 & group == \"INCR\") %>%\n        print()\n\n# A tibble: 9 x 101\n  subject group timepoint   age height.T1 weight.T1 sj.max cmj.max lac.125\n    <dbl> <chr> <chr>     <dbl>     <dbl>     <dbl>  <dbl>   <dbl>   <dbl>\n1       1 INCR  pre          33       183      80.3   31.0    35.0    1.5 \n2       3 INCR  pre          39       193      98.1   26.8    28.8    1.17\n3      20 INCR  pre          42       180      82.3   32.5    32.2    2.26\n4       3 INCR  meso1        39        NA     101.    26.0    26.5    0.72\n5      20 INCR  meso1        42        NA      82.5   30.2    30.6    0.96\n6       3 INCR  meso2        39        NA      99.2   25.4    26.8    0.5 \n7      20 INCR  meso2        42        NA      81.1   29.6    29.8    1.53\n8       3 INCR  meso3        39        NA      99.2   27.1    27.0    0.77\n9      20 INCR  meso3        43        NA      81.5   30.0    30.9    1.77\n# ... with 92 more variables: lac.175 <dbl>, lac.225 <dbl>, lac.250 <dbl>,\n#   lac.275 <dbl>, lac.300 <dbl>, lac.325 <dbl>, lac.350 <dbl>, lac.375 <dbl>,\n#   VO2.125 <dbl>, VO2.175 <dbl>, VO2.225 <dbl>, VO2.250 <dbl>, VO2.275 <dbl>,\n#   VO2.300 <dbl>, VO2.325 <dbl>, VO2.350 <dbl>, VO2.375 <dbl>, VCO2.125 <dbl>,\n#   VCO2.175 <dbl>, VCO2.225 <dbl>, VCO2.250 <dbl>, VCO2.275 <dbl>,\n#   VCO2.300 <dbl>, VCO2.325 <dbl>, VCO2.350 <dbl>, VCO2.375 <dbl>,\n#   VE.125 <dbl>, VE.175 <dbl>, VE.225 <dbl>, VE.250 <dbl>, VE.275 <dbl>, ...\n\n\nWe can similarly use OR (|) to select either weight greater than 80 or group INCR.\n\n#| echo: true\n\ncyclingstudy %>%\n        filter(weight.T1 > 80 | group == \"INCR\") %>%\n        print()\n\n# A tibble: 46 x 101\n   subject group timepoint   age height.T1 weight.T1 sj.max cmj.max lac.125\n     <dbl> <chr> <chr>     <dbl>     <dbl>     <dbl>  <dbl>   <dbl>   <dbl>\n 1       1 INCR  pre          33       183      80.3   31.0    35.0    1.5 \n 2       3 INCR  pre          39       193      98.1   26.8    28.8    1.17\n 3       5 DECR  pre          31       176      88     31.2    25.8    1.06\n 4       6 INCR  pre          33       168      79.6   34.2    35.3    1.27\n 5       9 MIX   pre          41       185      82.4   22.7    22.4    1.48\n 6      10 INCR  pre          35       187      75.6   29.7    31.1    0.93\n 7      14 MIX   pre          35       183      81.3   27.6    30.0    1.13\n 8      15 INCR  pre          34       178      75.1   33.5    32.4    0.8 \n 9      16 INCR  pre          27       178      77.8   32.9    33.7    0.94\n10      18 DECR  pre          41       186     105.    33.5    33.7    1.75\n# ... with 36 more rows, and 92 more variables: lac.175 <dbl>, lac.225 <dbl>,\n#   lac.250 <dbl>, lac.275 <dbl>, lac.300 <dbl>, lac.325 <dbl>, lac.350 <dbl>,\n#   lac.375 <dbl>, VO2.125 <dbl>, VO2.175 <dbl>, VO2.225 <dbl>, VO2.250 <dbl>,\n#   VO2.275 <dbl>, VO2.300 <dbl>, VO2.325 <dbl>, VO2.350 <dbl>, VO2.375 <dbl>,\n#   VCO2.125 <dbl>, VCO2.175 <dbl>, VCO2.225 <dbl>, VCO2.250 <dbl>,\n#   VCO2.275 <dbl>, VCO2.300 <dbl>, VCO2.325 <dbl>, VCO2.350 <dbl>,\n#   VCO2.375 <dbl>, VE.125 <dbl>, VE.175 <dbl>, VE.225 <dbl>, VE.250 <dbl>, ...\n\n\nNotice that there are rows containing weights less than 80 from the INCR group.\nAny logical statement can also be negated with ! indication NOT. This means we will get a vector of TRUE for any expression previously being FALSE. Notice the extra parentheses below.\n\n#| echo: true\n\ncyclingstudy %>%\n        filter(!(weight.T1 > 80 & group == \"INCR\")) %>%\n        print()\n\n# A tibble: 71 x 101\n   subject group timepoint   age height.T1 weight.T1 sj.max cmj.max lac.125\n     <dbl> <chr> <chr>     <dbl>     <dbl>     <dbl>  <dbl>   <dbl>   <dbl>\n 1       2 DECR  pre          32       174      71.4   31.6    33.8    1.19\n 2       4 DECR  pre          37       175      79.2   29.2    30.8    0.88\n 3       5 DECR  pre          31       176      88     31.2    25.8    1.06\n 4       6 INCR  pre          33       168      79.6   34.2    35.3    1.27\n 5       7 MIX   pre          42       180      77.6   30.1    33.0    0.85\n 6       8 MIX   pre          26       179      75.5   32.8    33.2    0.93\n 7       9 MIX   pre          41       185      82.4   22.7    22.4    1.48\n 8      10 INCR  pre          35       187      75.6   29.7    31.1    0.93\n 9      11 MIX   pre          34       168      55.8   33.2    30.8    0.62\n10      13 DECR  pre          41       183      76     34.3    36      1.67\n# ... with 61 more rows, and 92 more variables: lac.175 <dbl>, lac.225 <dbl>,\n#   lac.250 <dbl>, lac.275 <dbl>, lac.300 <dbl>, lac.325 <dbl>, lac.350 <dbl>,\n#   lac.375 <dbl>, VO2.125 <dbl>, VO2.175 <dbl>, VO2.225 <dbl>, VO2.250 <dbl>,\n#   VO2.275 <dbl>, VO2.300 <dbl>, VO2.325 <dbl>, VO2.350 <dbl>, VO2.375 <dbl>,\n#   VCO2.125 <dbl>, VCO2.175 <dbl>, VCO2.225 <dbl>, VCO2.250 <dbl>,\n#   VCO2.275 <dbl>, VCO2.300 <dbl>, VCO2.325 <dbl>, VCO2.350 <dbl>,\n#   VCO2.375 <dbl>, VE.125 <dbl>, VE.175 <dbl>, VE.225 <dbl>, VE.250 <dbl>, ...\n\n\nThe dplyr function filter also accepts multiple arguments separated with a comma. This is equal to adding conditions with the AND operator. Example:\n\n#| echo: true\n\ncyclingstudy %>%\n        filter(weight.T1 > 80, \n               group == \"INCR\", \n               timepoint == \"pre\", \n               age > 35) %>%\n        print()\n\n# A tibble: 2 x 101\n  subject group timepoint   age height.T1 weight.T1 sj.max cmj.max lac.125\n    <dbl> <chr> <chr>     <dbl>     <dbl>     <dbl>  <dbl>   <dbl>   <dbl>\n1       3 INCR  pre          39       193      98.1   26.8    28.8    1.17\n2      20 INCR  pre          42       180      82.3   32.5    32.2    2.26\n# ... with 92 more variables: lac.175 <dbl>, lac.225 <dbl>, lac.250 <dbl>,\n#   lac.275 <dbl>, lac.300 <dbl>, lac.325 <dbl>, lac.350 <dbl>, lac.375 <dbl>,\n#   VO2.125 <dbl>, VO2.175 <dbl>, VO2.225 <dbl>, VO2.250 <dbl>, VO2.275 <dbl>,\n#   VO2.300 <dbl>, VO2.325 <dbl>, VO2.350 <dbl>, VO2.375 <dbl>, VCO2.125 <dbl>,\n#   VCO2.175 <dbl>, VCO2.225 <dbl>, VCO2.250 <dbl>, VCO2.275 <dbl>,\n#   VCO2.300 <dbl>, VCO2.325 <dbl>, VCO2.350 <dbl>, VCO2.375 <dbl>,\n#   VE.125 <dbl>, VE.175 <dbl>, VE.225 <dbl>, VE.250 <dbl>, VE.275 <dbl>, ...\n\n\nFinally, dplyr comes with two convenient functions to find values between and near\n\n\n\n\n\n\nReview your understanding\n\n\n\n\n\n\nKeep rows in your data frame from the pre time-point, age greater than 31 but height less than 180.\nUse between to find rows with VO2.max values between 4800 and 5200 (see ?between)\nUse near to find weight.T1 values close to 80.26 with a tolerance of 0.75 (see ?near)\nRemove all rows that are NA in the height.T1 variable.\n\n\n\n\n\n\n\n\nA super power of dplyr is its ability to group and summarize data. The group_by function creates a grouped data frame suitable for summaries per group. In the cyclingstudy data set we have three groups that we might want to describe using some summary function.\nExamples of summary functions in R are:\n\nmean() → computes arithmetic mean\nmedian() → computes the median\nsd() → computes the standard deviation from the mean\nIQR() → returns the inter-quartile range\nmin() and max() → gives the minimum and maximum values from a vector\nquantile() → sample quantiles from the smallest (probs = 0) to largest (probs = 1) values.\nAll the above functions comes with the optional argument of na.rm = TRUE. This can be read as remove missing values (NA). If there are missing values (NA) and na.rm = FALSE (the default), the calculations will return NA. This is inconvenient but can often work as a sanity check of your code.\n\n\n\n\n\n\n\nReview your understanding\n\n\n\n\n\n\nWhat do we mean by sanity check?\nWhat do you expect from the R code sd(c(4, 5, 7, NA, 5))\nWhat would you add to the code above to improve it?\n\n\n\n\nIn addition to the summaries above that are generic for base R, dplyr provides you with a number of great functions to…\n\nn() → count the number of observations in each group\nn_distinct() → return the number of unique values from a vector for each group\n\nIn practice a grouped summary may look like this:\n\ncyclingstudy %>%\n        group_by(group) %>%\n        summarise(mean.vo2max = mean(VO2.max, na.rm = TRUE))\n\nResults from the above code includes multiple data points from each participant. The variable describing time-points can be added to the grouping.\n\ncyclingstudy %>%\n        group_by(group, timepoint) %>%\n        summarise(mean.vo2max = mean(VO2.max, na.rm = TRUE))\n\nMultiple summary functions can be added to the summarise() function where each adds a new variable to the result data frame.\n\ncyclingstudy %>%\n        group_by(group, timepoint) %>%\n        summarise(mean.vo2max = mean(VO2.max, na.rm = TRUE), \n                  sd.vo2max = sd(VO2.max, na.rm = TRUE))\n\n\n\n\nData not always in a form that makes tables, graphs or statistical methods directly available. Data can be described as being in long form and wide form. The long form data is tidy in the sense that all columns are distinct variables.\n\nThere are examples of wide data sets as part of the cycling data set. Using only the timepoint == pre values and columns corresponding to lactate values from the graded exercise test we have an example of wide data as the columns lac.125, lac.175, lac.225, etc., contains lactate values from different exercise intensities. This means that a separate variable (watt or exercise intensity) is combined in each column of lactate values.\n\ncyclingstudy %>%\n        filter(timepoint == \"pre\") %>%\n        dplyr::select(subject, group, lac.125:lac.375) %>%\n        print()\n\n# A tibble: 20 x 11\n   subject group lac.125 lac.175 lac.225 lac.250 lac.275 lac.300 lac.325 lac.350\n     <dbl> <chr>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1       1 INCR     1.5     1.86    2.38    3.54    6.21   NA      NA      NA   \n 2       2 DECR     1.19    1.49    2.34    3.21    5.33   NA      NA      NA   \n 3       3 INCR     1.17    1.52    1.22    1.54    2.04    3.32    4.72   NA   \n 4       4 DECR     0.88    0.99    2.13    3.25   NA       6.15   NA      NA   \n 5       5 DECR     1.06    1.41    1.9     2.04    3.04    3.59    4.73   NA   \n 6       6 INCR     1.27    1.73    3.21    4.83   NA      NA      NA      NA   \n 7       7 MIX      0.85    0.84    1.16    1.71    3.33    6.25   NA      NA   \n 8       8 MIX      0.93    1.34    1.94   NA       3.71    7.29   NA      NA   \n 9       9 MIX      1.48    1.17    1.95   NA       3.24    6.21   NA      NA   \n10      10 INCR     0.93    0.87    0.86    0.92    1.2     1.69    2.6     4.69\n11      11 MIX      0.62    1.22    2.85    5.86    9.87   NA      NA      NA   \n12      13 DECR     1.67    1.81    2.78    4.25    6.87   NA      NA      NA   \n13      14 MIX      1.13    1.33    2.74    3.97   NA      NA      NA      NA   \n14      15 INCR     0.8     1.12    1.43   NA       2.4     3.77    6.3    NA   \n15      16 INCR     0.94    1.18    1.89    2.83    5.33   NA      NA      NA   \n16      17 MIX      1.54    1.62    2.7     4.1    NA      NA      NA      NA   \n17      18 DECR     1.75    2.08    2.99    4.22   NA      NA      NA      NA   \n18      19 DECR     1.23    2.51    4.65   NA      NA      NA      NA      NA   \n19      20 INCR     2.26    2.05    3.19    5.17   NA      NA      NA      NA   \n20      21 DECR     0.68    0.89    1.98    3.18    5.57   NA      NA      NA   \n# ... with 1 more variable: lac.375 <dbl>\n\n\nUsing pivot_longer we can change this data into a long format. Pivot wider needs information on the new variable names for values and names. Names are the column names thta will form a variable and values are the values contained in the cells of the old variables. We also need to specify what columns to make longer, notice that I select variables <from>:<to>.\n\ncyclingstudy %>%\n        filter(timepoint == \"pre\") %>%\n        dplyr::select(subject, group, lac.125:lac.375) %>%\n        pivot_longer(names_to = \"watt\", \n                     values_to = \"lactate\", \n                     cols = lac.125:lac.375) %>%\n        print()\n\n# A tibble: 180 x 4\n   subject group watt    lactate\n     <dbl> <chr> <chr>     <dbl>\n 1       1 INCR  lac.125    1.5 \n 2       1 INCR  lac.175    1.86\n 3       1 INCR  lac.225    2.38\n 4       1 INCR  lac.250    3.54\n 5       1 INCR  lac.275    6.21\n 6       1 INCR  lac.300   NA   \n 7       1 INCR  lac.325   NA   \n 8       1 INCR  lac.350   NA   \n 9       1 INCR  lac.375   NA   \n10       2 DECR  lac.125    1.19\n# ... with 170 more rows\n\n\npivot_wider makes it easy to remove prefix and fix the data type of the names variable. Below we specify to remove lac. from all names and convert the new variable to numeric data.\n\ncyclingstudy %>%\n        filter(timepoint == \"pre\") %>%\n        dplyr::select(subject, group, lac.125:lac.375) %>%\n        pivot_longer(names_to = \"watt\", \n                     values_to = \"lactate\", \n                     cols = lac.125:lac.375, \n                     names_prefix = \"lac.\", \n                     names_transform = list(watt = as.numeric)) %>%\n        print()\n\n# A tibble: 180 x 4\n   subject group  watt lactate\n     <dbl> <chr> <dbl>   <dbl>\n 1       1 INCR    125    1.5 \n 2       1 INCR    175    1.86\n 3       1 INCR    225    2.38\n 4       1 INCR    250    3.54\n 5       1 INCR    275    6.21\n 6       1 INCR    300   NA   \n 7       1 INCR    325   NA   \n 8       1 INCR    350   NA   \n 9       1 INCR    375   NA   \n10       2 DECR    125    1.19\n# ... with 170 more rows\n\n\n\n\n\n\n\n\nReview your understanding\n\n\n\n\n\nPerform the opposite operation of the below data set:\n\ndata.frame(id = c(\"id1\", \"id1\", \"id1\", \"id2\", \"id2\", \"id2\"), \n           NAME = c(\"a\", \"b\", \"c\", \"a\", \"b\", \"c\"), \n           NUMBER = c(4, 6, 7, 2, 3, 5)) %>%\n\n        print()\n\n\n\n\n\n\n\nTable 1 in experimental or observational studies often contains descriptive data on the sample. These tables may help readers to understand to what group/population a study may be generalized to and how key characteristics are distributed among experimental groups.\nWe will prepare data from cyclingstudy to create a Table 1 with descriptive data:\n\nSelect a set of key variables that you want to describe (center, spread and/or range) from baseline measurements\nGroup the data set on group and perform summary calculations\n\n\n\nTo display numbers with the correct number of decimals R provides many options. A simple function (round()) provides rounding. The problem is that you will lose trailing zero, e.g., 2.0 will be displayed as 2. To keep the trailing zero we must use the sprintf() function. Examples:\n\n# Rounding\nround(2.10, 2) \n\n[1] 2.1\n\n# Formatting to keep the trailing zero\nsprintf(\"%.2f\", 2.10)\n\n[1] \"2.10\"\n\n\nCombining vectors may be a good idea to make the table more attractive. The mean and standard deviation is commonly presented as mean (SD). Data from a column of means and a column of SD’s can be combined to create a nice display using the paste0() function. Example:\n\ndata.frame(m = c(46.7, 47.89, 43.5),  # A vector of means\n           s = c(4.21, 4.666, 3.1)) %>% # A vector of SD's\n        mutate(stat = paste0(round(m, 1), \n                             \" (\",\n                             round(s, 1), \n                             \")\")) %>%\n        print()\n\n      m     s       stat\n1 46.70 4.210 46.7 (4.2)\n2 47.89 4.666 47.9 (4.7)\n3 43.50 3.100 43.5 (3.1)\n\n\nA character vector of group names can be arranged and re-named using the factor function. In the cyclingstudy data set the groups (INCR, DECR and MIX) may be given more descriptive names, example:\n\ncyclingstudy %>%\n        mutate(group = factor(group, levels = c(\"INCR\", \"DECR\", \"MIX\"), \n                              labels = c(\"Increased intensity\", \n                                         \"Decreased intensity\", \n                                         \"Mixed intensity\"))) %>%\n        distinct(group)\n\n# A tibble: 3 x 1\n  group              \n  <fct>              \n1 Increased intensity\n2 Decreased intensity\n3 Mixed intensity    \n\n\n\n\n\n\nWe will use a table generator to create the table. See next part of this workshop here"
  },
  {
    "objectID": "ws4b-tables.html",
    "href": "ws4b-tables.html",
    "title": "Quantitative Methods - Workshop, Assigments and Tutorials",
    "section": "",
    "text": "Footnotes\n\n\nQuarto was released on the 28:th of July 2022↩︎\nSee the list at the bottom of the gt package webpage↩︎"
  },
  {
    "objectID": "ws5-writing-reports.html",
    "href": "ws5-writing-reports.html",
    "title": "Writing reports and working with R projects",
    "section": "",
    "text": "These workshop notes contains links to relevant documentation-"
  },
  {
    "objectID": "ws5-writing-reports.html#quarto-and-rmarkdown",
    "href": "ws5-writing-reports.html#quarto-and-rmarkdown",
    "title": "Writing reports and working with R projects",
    "section": "Quarto and Rmarkdown",
    "text": "Quarto and Rmarkdown\n\nQuarto and R Markdown a special kind of scripts where text and computer code can be combined to generate reports.\nUnder the hood, a report generator is converting code and plain text to an output format such as html, pdf or docx (more formats are available).\nQuarto is a new, well documented format that gives extra flexibility, but also requires installation of extra software.\nR Markdown is even more well documented, see e.g. R Markdown, R Markdown: The Definitev Guide"
  },
  {
    "objectID": "ws5-writing-reports.html#code-execution-and-the-environment",
    "href": "ws5-writing-reports.html#code-execution-and-the-environment",
    "title": "Writing reports and working with R projects",
    "section": "Code execution and the environment",
    "text": "Code execution and the environment\n\nWhen a quarto or Rmarkdown file is “knitted”, the source file looks for e.g., data files in the same directory as the source file is saved.\nWorking in a RStudio projects makes it easy to work with the report interactively as you can use relative paths.\nRStudio has an excellent guide to its project feature"
  },
  {
    "objectID": "ws5-writing-reports.html#rstudio-projects",
    "href": "ws5-writing-reports.html#rstudio-projects",
    "title": "Writing reports and working with R projects",
    "section": "RStudio projects",
    "text": "RStudio projects\n\nA projects is basically a collection of settings together with a root directory.\nSettings can be accessed in Tools > Project Options.\nThis means that you will be able to work with relative paths. If reading a csv file using relative paths, your code will look like this from a project.\n\n\ndat <- read_csv(\"./data/my-data.csv\")\n\n\nIf your are using absolute paths, reaching the same goal could look like this\n\n\ndat <- read_csv(\"C:/Users/Daniel/Dropbox/Some-folder/a-project/data/my-data.csv\")\n\n\nRStudio projects helps you create good habits for reproducible analysis as all analyses are conducted within a stand-alone folder structure. Your data and scripts can be shared.\nUse a basic structure for all projects:\n\nMy-project\n        |\n        |-.Rproj        (The project settings)\n        |--/data        (Contains all data needed for your analysis)\n        |--/R           (Contains all scripts/R-files)\n        |--/output      (Collection of all output files)\n\n\n\nStart a new project from the Project menu."
  },
  {
    "objectID": "ws5-writing-reports.html#writing-in-quartor-markdown",
    "href": "ws5-writing-reports.html#writing-in-quartor-markdown",
    "title": "Writing reports and working with R projects",
    "section": "Writing in Quarto/R Markdown",
    "text": "Writing in Quarto/R Markdown\n\nThe basic syntax in quarto/R Markdown files is markdown. Markdown makes it easy to format text without point-and-click as all formatting can be added with syntax, example:\n\nThis text is an example of the markdown syntax which includes **bold**, *italic*,\n^super^ and ~subscript~ and ~~striketrough~~\nResulting in:\n\nThis text is an example of the markdown syntax which includes bold, italic, super and subscript and striketrough\n\n\nIn addition to text formatting, the markdown syntax offers solutions for adding images, tables, equations, lists, diagrams, different highligt blocks. See the the quarto documentation for more information."
  },
  {
    "objectID": "ws5-writing-reports.html#code-chunks",
    "href": "ws5-writing-reports.html#code-chunks",
    "title": "Writing reports and working with R projects",
    "section": "Code chunks",
    "text": "Code chunks\n\nCode chunks are sections of your source file containing code. We primarily write R-code, but e.g., python is also possible.\nThe code chunk comes with several options specified in the top of the chunk using #|, such as:\n\n```{r}\n#| eval: true\n#| echo: true\n#| warning: false\n#| error: true\n#| include: false\n```\n\nNote that the #| is a “new” intervention, some documentation will still suggest that you use code chunk settings in the code chunk header."
  },
  {
    "objectID": "ws5-writing-reports.html#inline-code",
    "href": "ws5-writing-reports.html#inline-code",
    "title": "Writing reports and working with R projects",
    "section": "Inline code",
    "text": "Inline code\n\nCode may be included inline to include code generated outputs\n\n\na_variable <- 3.14\n\n\nTo include the variable in the text:\n\n\nThe variable will be displayed here `r a_variable`"
  },
  {
    "objectID": "ws5-writing-reports.html#bibliographies",
    "href": "ws5-writing-reports.html#bibliographies",
    "title": "Writing reports and working with R projects",
    "section": "Bibliographies",
    "text": "Bibliographies\n\nBibliographies/Citations may be added to reports using a external bibliography file. A simple format is bibtex\nPubmed entries can be searched using TexMed\nIn the visual editor, bibliographies can be easily created"
  },
  {
    "objectID": "ws5-writing-reports.html#some-notes-on-different-formats",
    "href": "ws5-writing-reports.html#some-notes-on-different-formats",
    "title": "Writing reports and working with R projects",
    "section": "Some notes on different formats",
    "text": "Some notes on different formats\n\nHTML is the basic output from R Markdown and quarto. This is suitable for first drafts.\nTo be able to render PDF files you must have an installation of rendering software. TinyTeX is generally recomended, see the documentation and installation instructions here\nWord documents creates an editable document with associated pros and cons.\nAll formats has different advantages and offer flexibility that gives opportunities to create any type of document\nOther formats such as presentations, webpages, apps etc. makes quarto / R Markdown very versatile."
  },
  {
    "objectID": "ws6-git.html",
    "href": "ws6-git.html",
    "title": "Collaborative coding with github",
    "section": "",
    "text": "Jennifer Bryan has written an excellent paper (Bryan 2017) on the use of git and GitHub when working with R.\nJennifer is also co-author on the web-book “Happy Git and GitHub for the useR” which is an excellent resource whenever you are stuck.\n\n\nGit is a version control system. It keeps track of changes made to files contained in a repository. Additionally, using GitHub users can collaborate on a repository by keeping an online version of the repository.\nThe benefits of using git comes from enabling collaboration with other and your future you (Bryan 2017)."
  },
  {
    "objectID": "ws6-git.html#different-alternatives-for-version-control",
    "href": "ws6-git.html#different-alternatives-for-version-control",
    "title": "Collaborative coding with github",
    "section": "Different alternatives for version control",
    "text": "Different alternatives for version control\n\n\n\n(Figure from Bryan 2017)"
  },
  {
    "objectID": "ws6-git.html#basic-git-and-github",
    "href": "ws6-git.html#basic-git-and-github",
    "title": "Collaborative coding with github",
    "section": "Basic git and GitHub",
    "text": "Basic git and GitHub\n\nCreate new repositories online on github, this will be an empty repository\nClone the repository in your R project (New Project > Version Control > Git)\nMake changes, add files etc.\ngit add file for a specific file or git add -A for all changed files\ngit commit -m \"message\" commit changes to the version control system with a message describing what you have done.\ngit push to the remote repository (GitHub)\nIf collaborating, a collaborator may git pull all changes to their local repository.\nCheck if you have any changes that needs to be commited or pulled by git status\n\n\nUsing forks and pull requests\n\nA fork is a copy of a repository that may evolve independently to the original repository under your own username on github.\nCreate a fork from the GitHub web interface (www.github.com).\nAfter you have made changes you may file a pull request to the original repository. You will have to describe the changes and why you think the maintainer should accept pulling your changes into the original repository.\nThis is a great way to suggest changes to complex projects.\n\n\n\nUsing branches\n\nSimilarly to forks, a branch can also be used to update a repository with changes which are then merged to the main branch after testing or review.\nSee the GitHub documentation for details."
  }
]